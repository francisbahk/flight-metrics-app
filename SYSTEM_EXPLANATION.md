# Flight Ranking System: Complete Technical Explanation

## Overview

Your app takes a natural language flight query, searches for flights, ranks them using 3 algorithms (including LISTEN-U), and collects user feedback on rankings.

**Architecture Summary**:
1. **Gemini LLM** parses natural language â†’ structured search params
2. **Amadeus API** searches real flights
3. **Three algorithms** rank flights independently
4. **Streamlit UI** shows interleaved results + collects feedback

**LISTEN Integration**: We use the core LISTEN classes (`BatchDuelingBanditOptimizer`, Gaussian Process model) from https://github.com/AdamJovine/LISTEN directly - NOT the main.py experimental framework. We've built a custom wrapper that adapts flight data to LISTEN's format and uses Gemini for preference comparisons.

---

## Part 1: User Prompt â†’ Gemini Parsing

### What Happens

**Location**: [backend/prompt_parser.py](backend/prompt_parser.py)

When you type something like:
```
"I need to fly from Ithaca NY to Washington DC on October 20th.
I prefer direct flights and want to avoid early morning departures."
```

### Step-by-Step Process

#### 1. Gemini LLM Call ([prompt_parser.py:21-113](backend/prompt_parser.py#L21-L113))

The app sends your prompt to Gemini 2.0-flash with a **structured instruction**:

```python
model = genai.GenerativeModel('gemini-2.0-flash')
response = model.generate_content(llm_prompt)
```

The `llm_prompt` includes:
- Your user query
- Instructions to extract specific fields
- Airport code mappings (ITH â†’ Ithaca, DCA/IAD â†’ Washington DC)
- Today's date for relative date parsing

#### 2. What Gemini Returns

Gemini returns a JSON object:

```json
{
  "origins": ["ITH"],
  "destinations": ["DCA", "IAD"],
  "departure_date": "2024-10-20",
  "return_date": null,
  "preferences": {
    "prefer_direct": true,
    "prefer_cheap": false,
    "prefer_fast": false,
    "avoid_early_departures": true,
    "min_connection_time": 45,
    "max_layover_time": 90,
    "preferred_airlines": [],
    "avoid_airports": [],
    "fly_america_act": false
  },
  "constraints": {
    "latest_arrival": null,
    "earliest_departure": "07:00"
  }
}
```

#### 3. Parsing the Response ([prompt_parser.py:84-108](backend/prompt_parser.py#L84-L108))

The code:
- Strips markdown formatting (````json` blocks)
- Parses JSON
- Validates required fields (origins, destinations)
- Falls back to regex parsing if Gemini fails

### Key Intelligence

Gemini understands:
- **City names â†’ Airport codes**: "Ithaca NY" â†’ ["ITH"]
- **Multiple airports**: "Washington DC" â†’ ["DCA", "IAD"]
- **Implicit preferences**: "cheap as possible" â†’ `prefer_cheap: true`
- **Relative dates**: "next Tuesday" â†’ actual date
- **Time constraints**: "before 7am" â†’ `earliest_departure: "07:00"`

---

## Part 2: Flight Search (Amadeus API)

### What Happens

**Location**: [backend/amadeus_client.py](backend/amadeus_client.py), [app_new.py:125-193](app_new.py#L125-L193)

#### 1. OAuth2 Authentication ([amadeus_client.py:54-95](backend/amadeus_client.py#L54-L95))

```python
# Get access token
response = requests.post(
    self.AUTH_URL,
    data={
        "grant_type": "client_credentials",
        "client_id": self.api_key,
        "client_secret": self.api_secret,
    }
)
self.access_token = data["access_token"]
```

**Tokens are cached** for ~30 minutes, so subsequent searches don't re-authenticate.

#### 2. Flight Search Request ([amadeus_client.py:97-171](backend/amadeus_client.py#L97-L171))

```python
response = requests.get(
    self.FLIGHT_OFFERS_URL,
    headers={"Authorization": f"Bearer {token}"},
    params={
        "originLocationCode": "ITH",
        "destinationLocationCode": "DCA",
        "departureDate": "2024-10-20",
        "adults": 1,
        "max": 50
    }
)
```

Returns up to 50 flights with:
- Price, duration, stops
- Departure/arrival times
- Airline codes
- Full itinerary segments

#### 3. Data Transformation ([backend/utils/parse_duration.py](backend/utils/parse_duration.py))

Amadeus returns ISO 8601 durations like `"PT5H30M"`.

We parse this into minutes:
- `PT5H30M` â†’ 330 minutes (5 hours, 30 minutes)

Each flight becomes:
```python
{
    'id': 'unique_id',
    'price': 299.0,
    'duration_min': 330,
    'stops': 1,
    'departure_time': '2024-10-20T08:00:00',
    'arrival_time': '2024-10-20T13:30:00',
    'origin': 'ITH',
    'destination': 'DCA',
    'airline': 'UA',
    'flight_number': '1234'
}
```

---

## Part 3: Running the 3 Algorithms

### Algorithm 1: Cheapest ([app_new.py:199](app_new.py#L199))

Simple sort by price:
```python
cheapest_ranked = sorted(all_flights, key=lambda x: x['price'])[:10]
```

Returns top 10 cheapest flights.

### Algorithm 2: Fastest ([app_new.py:202](app_new.py#L202))

Simple sort by duration:
```python
fastest_ranked = sorted(all_flights, key=lambda x: x['duration_min'])[:10]
```

Returns top 10 fastest flights.

### Algorithm 3: LISTEN-U (LLM-Based Dueling Bandit)

**Location**: [backend/listen_wrapper.py](backend/listen_wrapper.py)

This is the **complex one**! Let me break it down step by step.

---

## Part 4: LISTEN-U Deep Dive

### What is LISTEN-U?

**LISTEN-U** (Learning to Identify STakeholder ENgagement Utility) is a **dueling bandit optimization algorithm** that learns user preferences by:
1. Comparing pairs of flights
2. Asking an LLM which is better
3. Learning a utility function from comparisons

### Step 1: Feature Extraction ([listen_wrapper.py:21-117](backend/listen_wrapper.py#L21-L117))

**Convert flights to 7-dimensional feature vectors:**

```python
features = flights_to_listen_features(flights, user_preferences)
```

| Feature | Source | Normalization |
|---------|--------|---------------|
| `price_norm` | `flight['price']` | `price / max_price` (0-1) |
| `duration_norm` | `flight['duration_min']` | `duration / max_duration` (0-1) |
| `stops` | `flight['stops']` | `min(stops, 2) / 2.0` (0-1) |
| `dep_norm` | `flight['departure_time']` | `hour_of_day / 24.0` (0-1) |
| `arr_norm` | `flight['arrival_time']` | `hour_of_day / 24.0` (0-1) |
| `dis_from_origin` | User pref vs actual | 0 = match, 1 = mismatch |
| `dis_from_dest` | User pref vs actual | 0 = match, 1 = mismatch |

**Example**:
```python
Flight UA1234: $299, 330 min, 1 stop, departs 8am, arrives 1:30pm
â†’ [0.65, 0.55, 0.5, 0.33, 0.56, 0.0, 0.0]
```

### Step 2: Initialize LLM Client ([listen_wrapper.py:155-173](backend/listen_wrapper.py#L155-L173))

```python
client = GeminiLLMPreferenceClient(
    api_key=gemini_key,
    model_name="gemini-2.0-flash",
    rate_limit_delay=0.2,
    max_tokens=512,
    max_retries=10
)
```

This client talks to Gemini to compare flights.

### Step 3: Initialize Dueling Bandit Optimizer ([listen_wrapper.py:175-184](backend/listen_wrapper.py#L175-L184))

```python
optimizer = DuelingBanditOptimizer(
    all_options=list(range(len(flights))),  # [0, 1, 2, ..., 49]
    features=features,                      # 50 x 7 matrix
    client=client,                          # Gemini client
    batch_size=4,                           # 4 comparisons per iteration
    n_champions=10,                         # Track top 10
    acquisition="eubo"                      # Expected Utility-Based Optimization
)
```

### Step 4: Iterative Comparison ([listen_wrapper.py:192-246](backend/listen_wrapper.py#L192-L246))

**For 5 iterations:**

#### Iteration 1-5:

1. **Select next batch** of 4 flight pairs to compare:
```python
batch = optimizer.select_next_batch()
# Returns: [(3, 17), (8, 24), (12, 31), (5, 42)]
```

2. **For each pair, create comparison prompt**:
```python
comparison_text = f"""
Flight A: UA1234
- Price: $299
- Duration: 330 min
- Stops: 1

Flight B: AA5678
- Price: $450
- Duration: 240 min
- Stops: 0

User wants: I prefer direct flights and want to avoid early morning departures

Which flight is better for this user?
"""
```

3. **Get LLM preference** (currently **simulated** - see note below):
```python
# Currently using feature-based heuristic:
score_a = -features[option_a_idx, 0] - features[option_a_idx, 1] - features[option_a_idx, 2]
score_b = -features[option_b_idx, 0] - features[option_b_idx, 1] - features[option_b_idx, 2]
winner_idx = option_a_idx if score_a > score_b else option_b_idx
```

**NOTE**: The LLM comparison is **currently simulated** using a simple heuristic (lines 224-229). To use real Gemini comparisons, you'd call:
```python
choice, text = client.call_oracle(comparison_text)
```

4. **Record comparison result**:
```python
result = ComparisonResult(
    option_a=option_a_idx,
    option_b=option_b_idx,
    winner=winner_idx,
    features_a=features[option_a_idx],
    features_b=features[option_b_idx]
)
optimizer.comparison_history.append(result)
```

5. **Train Gaussian Process model** on all comparisons:
```python
optimizer._train_model_on_all_data()
```

The GP learns a **utility function** `U(flight)` that predicts which flights the user prefers.

6. **Update champions** (top 10 flights):
```python
optimizer._update_champions()
```

### Step 5: Final Ranking ([listen_wrapper.py:250-265](backend/listen_wrapper.py#L250-L265))

After 5 iterations:
```python
# Get learned utility for all flights
utilities = optimizer.model.posterior_mean_util(features)

# Rank by utility (highest first)
ranked_indices = np.argsort(utilities)[::-1]

# Return top 10
ranked_flights = [flights[i] for i in ranked_indices[:10]]
```

---

## Part 5: Round-Robin Interleaving

**Location**: [app_new.py:237-262](app_new.py#L237-L262)

Combine results from all 3 algorithms:

```python
interleaved = []
for i in range(10):
    if i < len(cheapest_ranked):
        interleaved.append({
            'flight': cheapest_ranked[i],
            'algorithm': 'Cheapest',
            'rank': i + 1
        })
    if i < len(fastest_ranked):
        interleaved.append({
            'flight': fastest_ranked[i],
            'algorithm': 'Fastest',
            'rank': i + 1
        })
    if i < len(listen_u_ranked):
        interleaved.append({
            'flight': listen_u_ranked[i],
            'algorithm': 'LISTEN-U',
            'rank': i + 1
        })
```

**Result**: 30 flights total (10 from each algorithm)

The user sees:
- Cheapest #1, Fastest #1, LISTEN-U #1
- Cheapest #2, Fastest #2, LISTEN-U #2
- ...
- Cheapest #10, Fastest #10, LISTEN-U #10

**Why interleave?**
- Users see diversity of options
- Prevents algorithm bias in feedback
- Allows fair comparison across algorithms

---

## Part 6: User Feedback Collection

### Flow

1. **User selects 5 flights** from the 30 shown
2. **User drags to reorder** their top 5
3. **User hits "Submit Rankings"**
4. **System records**:
   - Original prompt
   - 30 flights shown (with algorithm labels)
   - User's top 5 (in order)
   - Timestamp

### Why This Data is Valuable

For **offline evaluation**, you can:
- Compare algorithm rankings vs user rankings
- Calculate metrics like **NDCG** (Normalized Discounted Cumulative Gain)
- Measure **position bias** (do users prefer top results?)
- Train better ranking algorithms

---

## Key Technical Decisions

### 1. Why Gemini 2.0-flash?

**Speed + Cost**:
- Fast inference (~1-2 seconds)
- Low cost per call
- Good JSON output formatting

### 2. Why Simulate LISTEN-U LLM Comparisons?

**Cost + Speed**:
- Real LLM comparisons = 4 comparisons Ã— 5 iterations = 20 API calls per search
- At $0.01/call = $0.20 per search
- Simulated version is instant and free for testing

**To enable real comparisons**:
Replace lines 224-229 in [listen_wrapper.py](backend/listen_wrapper.py#L224-L229) with:
```python
choice, text = client.call_oracle(comparison_text)
winner_idx = option_a_idx if choice == 'A' else option_b_idx
```

### 3. Why 5 LISTEN-U Iterations?

**Balance**:
- More iterations = better learned utility, but slower
- 5 iterations = 20 comparisons = good approximation
- Can increase to 10-20 for better quality

### 4. Why Normalize Features to [0, 1]?

**GP Training**:
- Gaussian Processes work best with normalized features
- Prevents large-valued features (price) from dominating
- Makes learned weights interpretable

---

## Data Flow Diagram

```
User Prompt
    â†“
Gemini LLM (parse_flight_prompt_with_llm)
    â†“
{origins, destinations, date, preferences}
    â†“
Amadeus API (search_flights)
    â†“
50 raw flights
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cheapest   â”‚   Fastest    â”‚   LISTEN-U     â”‚
â”‚  (sort by   â”‚  (sort by    â”‚  (dueling      â”‚
â”‚   price)    â”‚   duration)  â”‚   bandit)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“          â†“              â†“
       Top 10     Top 10         Top 10
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
           Round-robin interleave
                    â†“
              30 flights shown
                    â†“
          User selects & ranks 5
                    â†“
            Save to database
```

---

## Performance Characteristics

### Latency Breakdown

| Step | Time | Notes |
|------|------|-------|
| Gemini parse | 1-2s | API call |
| Amadeus auth | 0.1s | Cached after first call |
| Amadeus search | 2-5s | Depends on route |
| Cheapest algo | <0.01s | Simple sort |
| Fastest algo | <0.01s | Simple sort |
| LISTEN-U feature extraction | 0.05s | NumPy operations |
| LISTEN-U iterations (simulated) | 0.1s | 5 iterations Ã— 4 comparisons |
| LISTEN-U GP training | 0.5s | scikit-learn GP |
| **Total** | **~4-8 seconds** | Mostly API calls |

With **real LLM comparisons**, add:
- 20 Gemini calls Ã— 0.5s each = **+10 seconds**
- **Total: ~15-20 seconds**

---

## Improvements & Extensions

### 1. Cache Gemini Prompts

Parse common queries once:
```python
@st.cache_data
def parse_flight_prompt_with_llm(prompt: str):
    ...
```

### 2. Use Real LISTEN-U Comparisons

Replace simulated scoring with actual LLM calls for better utility learning.

### 3. Add More Features

Expand from 7 to 10+ features:
- Layover duration
- Aircraft type
- Airline rating
- On-time performance
- Price change trends

### 4. Multi-Objective LISTEN

Learn separate utilities for:
- Price sensitivity
- Time sensitivity
- Comfort preferences

### 5. Active Learning

Use uncertainty sampling:
- Compare flights where GP is most uncertain
- Reduces comparisons needed

---

## Questions You Might Have

### Q: Why not just use ChatGPT to rank flights directly?

**A**: We want to **learn** what rankings work best, not hardcode them. LISTEN-U learns from user feedback to improve over time.

### Q: Can I use a different LLM (Claude, GPT-4)?

**A**: Yes! Just implement the `call_oracle()` interface in a new client class (see [gemini_llm_client.py](backend/gemini_llm_client.py) as template).

### Q: How do I make LISTEN-U faster?

**A**:
- Reduce iterations (5 â†’ 3)
- Reduce batch size (4 â†’ 2)
- Use cached GP model
- Pre-train on historical data

### Q: Can I add a 4th algorithm?

**A**: Yes! Just add another ranking function and include it in the interleaving loop:
```python
custom_ranked = your_algorithm(all_flights)[:10]

for i in range(10):
    # ... existing code ...
    if i < len(custom_ranked):
        interleaved.append({
            'flight': custom_ranked[i],
            'algorithm': 'Custom',
            'rank': i + 1
        })
```

---

## Summary

Your app is a **sophisticated flight ranking research platform** that:

1. **Parses natural language** with Gemini LLM
2. **Searches real flights** with Amadeus API
3. **Ranks with 3 algorithms**: Cheapest, Fastest, LISTEN-U (Gaussian Process dueling bandit)
4. **Collects user feedback** for offline evaluation
5. **Exports data** for analysis

The **LISTEN-U algorithm** is the star - it uses machine learning (Gaussian Process) to learn user preferences from pairwise comparisons, potentially discovering non-obvious preferences that simple heuristics miss.

**You now understand the entire codebase!** ðŸŽ‰
